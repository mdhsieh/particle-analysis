{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm-mask-rcnn-train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7hDd6DWpPjo"
      },
      "source": [
        "Recurrent Mask R-CNN Demo\n",
        "\n",
        "Ref: https://github.com/cechung/R-RCNN\n",
        "\n",
        "- Single Object Tracking\n",
        "- detection module: Matterport implementation Mask R-CNN\n",
        "- tracking module: 2 LSTM networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0oaSLH6DM7v",
        "outputId": "804e75aa-7a2d-450d-b091-995194f6ca7f"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9dlrTg7-vJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1ea1ee-919f-47ac-b1ee-0bd6ff1bcc11"
      },
      "source": [
        "# need tf 1.15.2\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlTzsqO_-vtQ",
        "outputId": "37fa6145-f998-46a6-cc57-1d9f0978d6f2"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VytNOELo_zj4",
        "outputId": "39892310-cd96-4537-89ab-11f01b34e9c5"
      },
      "source": [
        "# fix AttributeError: 'str' object has no attribute 'decode'\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJjy56EoBSjF",
        "outputId": "7518c1eb-1362-4873-f573-4a2a1401b860"
      },
      "source": [
        "# fix AttributeError: module 'scipy.misc' has no attribute 'imresize'\n",
        "!pip install scipy==1.2.2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.2.2 in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.2) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LprevodMDNkf",
        "outputId": "5fdc6b74-34b3-4f0b-9543-a68ce6e4adad"
      },
      "source": [
        "# go to folder containing LSTM_Mask_RCNN repo and outputs\n",
        "import os\n",
        "root = \"/content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/\"\n",
        "os.chdir(root)\n",
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "priTHD9iqjc6",
        "outputId": "9b743642-2912-4087-9b96-7aff27b348a8"
      },
      "source": [
        "# install requirements\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.2.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 8)) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->-r requirements.txt (line 8)) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRI0DyJOrYfG"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIpd1ZmuWsw"
      },
      "source": [
        "# use pre-trained weight kaggle_bowl.h5"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-H-RtFBJCO2"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b45n96IKmjXB"
      },
      "source": [
        "## inference demos of Mask R-CNN and Mask R-CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23gsZ4WUGCiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f924c1e0-c500-436f-da30-1b09bc359791"
      },
      "source": [
        "# demo mask r-cnn\n",
        "\n",
        "# detect images in demo_video_nucleus/frames.\n",
        "\n",
        "# The single image in demo_video_nucleus/frames/stage1_test/0000 can be detected using\n",
        "# nucleus.py from https://github.com/matterport/Mask_RCNN/tree/master/samples/nucleus\n",
        "# but is not detected using demo_mrcnn.py\n",
        "!python demo_mrcnn.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "\n",
            "Configurations:\n",
            "BACKBONE_SHAPES                [[160 160]\n",
            " [ 80  80]\n",
            " [ 40  40]\n",
            " [ 20  20]\n",
            " [ 10  10]]\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "GPU_COUNT                      1\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_MAX_DIM                  640\n",
            "IMAGE_MIN_DIM                  480\n",
            "IMAGE_PADDING                  True\n",
            "IMAGE_SHAPE                    [640 640   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:319: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:448: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:834: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "2021-07-21 02:00:20.328398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-21 02:00:20.438437: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-07-21 02:00:20.438543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6c525f5bd22c): /proc/driver/nvidia/version does not exist\n",
            "2021-07-21 02:00:20.499000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-07-21 02:00:20.499438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55973ae8ea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-21 02:00:20.499489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Image name: 0001.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "\n",
            "*** No instances in image 0001.jpg to draw *** \n",
            "\n",
            "Image name: 0002.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0002.jpg to draw *** \n",
            "\n",
            "Image name: 0003.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0003.jpg to draw *** \n",
            "\n",
            "Image name: 0004.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0004.jpg to draw *** \n",
            "\n",
            "Image name: 0005.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0005.jpg to draw *** \n",
            "\n",
            "Image name: 0006.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0006.jpg to draw *** \n",
            "\n",
            "Image name: 0007.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0007.jpg to draw *** \n",
            "\n",
            "Image name: 0008.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0008.jpg to draw *** \n",
            "\n",
            "Image name: 0009.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0009.jpg to draw *** \n",
            "\n",
            "Image name: 0010.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0010.jpg to draw *** \n",
            "\n",
            "Image name: 0011.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0011.jpg to draw *** \n",
            "\n",
            "Image name: 0012.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0012.jpg to draw *** \n",
            "\n",
            "Image name: 0013.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0013.jpg to draw *** \n",
            "\n",
            "Image name: 0014.jpg\n",
            "Processing 1 images\n",
            "image                    shape: (200, 200, 3)         min:    0.00000  max:  255.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0014.jpg to draw *** \n",
            "\n",
            "Image name: 0015.png\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:    1.00000  max:  147.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:   41.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0015.png to draw *** \n",
            "\n",
            "Image name: 0016.png\n",
            "Processing 1 images\n",
            "image                    shape: (256, 256, 3)         min:   10.00000  max:  125.00000\n",
            "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:   17.10000\n",
            "image_metas              shape: (1, 89)               min:    0.00000  max:  560.00000\n",
            "\n",
            "*** No instances in image 0016.png to draw *** \n",
            "\n",
            "\n",
            "# ------------------------------------ #\n",
            "# Processed Frames: 16\n",
            "# Cost Time: 126.983\n",
            "# FPS: 0.1\n",
            "# ------------------------------------ #\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Gwu6jfrWLxSA",
        "outputId": "786f7c4d-8591-44c1-c656-8ebff400d9db"
      },
      "source": [
        "# new script using nucleus.py from https://github.com/matterport/Mask_RCNN/tree/master/samples/nucleus\n",
        "'''\n",
        "# go to samples/nucleus folder in LSTM_Mask_RCNN repo\n",
        "import os\n",
        "root = \"/content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/samples/nucleus\"\n",
        "os.chdir(root)\n",
        "!pwd\n",
        "# import nucleus is only available in samples/nucleus directory\n",
        "import nucleus\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Dataset directory\n",
        "# DATASET_DIR = os.path.join(ROOT_DIR, \"single-particle-dataset/nucleus\")\n",
        "DATASET_DIR = os.path.join(ROOT_DIR, \"demo_video_nucleus/frames\")\n",
        "\n",
        "# Inference Configuration\n",
        "config = nucleus.NucleusInferenceConfig()\n",
        "config.display()\n",
        "\n",
        "# Device to load the neural network on.\n",
        "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# Only inference mode is supported right now\n",
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "# Load validation dataset\n",
        "dataset = nucleus.NucleusDataset()\n",
        "dataset.load_nucleus(DATASET_DIR, \"stage1_test\")\n",
        "\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
        "\n",
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\",\n",
        "                              model_dir=LOGS_DIR,\n",
        "                              config=config)\n",
        "\n",
        "# Path to a specific weights file\n",
        "weights_path = \"../../kaggle_bowl.h5\"\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "image_id = random.choice(dataset.image_ids)\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "info = dataset.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       dataset.image_reference(image_id)))\n",
        "print(\"Original image shape: \", modellib.parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\n",
        "\n",
        "# print(\"object detection using detect_molded()\")\n",
        "# # Run object detection\n",
        "# results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\n",
        "\n",
        "# # Display results\n",
        "# r = results[0]\n",
        "# log(\"gt_class_id\", gt_class_id)\n",
        "# log(\"gt_bbox\", gt_bbox)\n",
        "# log(\"gt_mask\", gt_mask)\n",
        "\n",
        "# # Compute AP over range 0.5 to 0.95 and print it\n",
        "# utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
        "#                        r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
        "#                        verbose=1)\n",
        "\n",
        "# visualize.display_differences(\n",
        "#     image,\n",
        "#     gt_bbox, gt_class_id, gt_mask,\n",
        "#     r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
        "#     dataset.class_names, ax=get_ax(),\n",
        "#     show_box=False, show_mask=False,\n",
        "#     iou_threshold=0.5, score_threshold=0.5)\n",
        "\n",
        "\n",
        "# regular detection function\n",
        "print(\"object detection using detect()\")\n",
        "img_name = str(image_id) + \".png\" # \".jpg\"\n",
        "import utils.utils as utils\n",
        "import utils.visualize as visualize\n",
        "coco_class_names = ['BG', 'cell']\n",
        "RESULT_DIR = os.path.join(ROOT_DIR, \"mrcnn_result\")\n",
        "regular_results = model.detect([image], verbose=1)\n",
        "reg_r = regular_results[0]\n",
        "# print(\"reg r:\", reg_r)\n",
        "# Visualize results\n",
        "visualize.save_image(image, img_name, reg_r['rois'], reg_r['masks'],\n",
        "  reg_r['class_ids'], reg_r['scores'], coco_class_names,\n",
        "  filter_classs_names=None, scores_thresh=0.1, \n",
        "  save_dir=RESULT_DIR, mode=1)\n",
        "\n",
        "print(\"Done\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# go to samples/nucleus folder in LSTM_Mask_RCNN repo\\nimport os\\nroot = \"/content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/samples/nucleus\"\\nos.chdir(root)\\n!pwd\\n# import nucleus is only available in samples/nucleus directory\\nimport nucleus\\n\\nimport os\\nimport sys\\nimport random\\nimport math\\nimport re\\nimport time\\nimport numpy as np\\nimport tensorflow as tf\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\nimport matplotlib.patches as patches\\n\\n# Root directory of the project\\nROOT_DIR = os.path.abspath(\"../../\")\\n\\n# Import Mask RCNN\\nsys.path.append(ROOT_DIR)  # To find local version of the library\\nfrom mrcnn import utils\\nfrom mrcnn import visualize\\nfrom mrcnn.visualize import display_images\\nimport mrcnn.model as modellib\\nfrom mrcnn.model import log\\n\\n%matplotlib inline \\n\\n# Directory to save logs and trained model\\nLOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\\n\\n# Dataset directory\\n# DATASET_DIR = os.path.join(ROOT_DIR, \"single-particle-dataset/nucleus\")\\nDATASET_DIR = os.path.join(ROOT_DIR, \"demo_video_nucleus/frames\")\\n\\n# Inference Configuration\\nconfig = nucleus.NucleusInferenceConfig()\\nconfig.display()\\n\\n# Device to load the neural network on.\\nDEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\\n\\n# Inspect the model in training or inference modes\\n# values: \\'inference\\' or \\'training\\'\\n# Only inference mode is supported right now\\nTEST_MODE = \"inference\"\\n\\ndef get_ax(rows=1, cols=1, size=16):\\n    \"\"\"Return a Matplotlib Axes array to be used in\\n    all visualizations in the notebook. Provide a\\n    central point to control graph sizes.\\n    \\n    Adjust the size attribute to control how big to render images\\n    \"\"\"\\n    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\\n    fig.tight_layout()\\n    return ax\\n\\n# Load validation dataset\\ndataset = nucleus.NucleusDataset()\\ndataset.load_nucleus(DATASET_DIR, \"stage1_test\")\\n\\ndataset.prepare()\\n\\nprint(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\\n\\n# Create model in inference mode\\nwith tf.device(DEVICE):\\n    model = modellib.MaskRCNN(mode=\"inference\",\\n                              model_dir=LOGS_DIR,\\n                              config=config)\\n\\n# Path to a specific weights file\\nweights_path = \"../../kaggle_bowl.h5\"\\n\\n# Load weights\\nprint(\"Loading weights \", weights_path)\\nmodel.load_weights(weights_path, by_name=True)\\n\\nimage_id = random.choice(dataset.image_ids)\\nimage, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\\ninfo = dataset.image_info[image_id]\\nprint(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \\n                                       dataset.image_reference(image_id)))\\nprint(\"Original image shape: \", modellib.parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\\n\\n# print(\"object detection using detect_molded()\")\\n# # Run object detection\\n# results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\\n\\n# # Display results\\n# r = results[0]\\n# log(\"gt_class_id\", gt_class_id)\\n# log(\"gt_bbox\", gt_bbox)\\n# log(\"gt_mask\", gt_mask)\\n\\n# # Compute AP over range 0.5 to 0.95 and print it\\n# utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\\n#                        r[\\'rois\\'], r[\\'class_ids\\'], r[\\'scores\\'], r[\\'masks\\'],\\n#                        verbose=1)\\n\\n# visualize.display_differences(\\n#     image,\\n#     gt_bbox, gt_class_id, gt_mask,\\n#     r[\\'rois\\'], r[\\'class_ids\\'], r[\\'scores\\'], r[\\'masks\\'],\\n#     dataset.class_names, ax=get_ax(),\\n#     show_box=False, show_mask=False,\\n#     iou_threshold=0.5, score_threshold=0.5)\\n\\n\\n# regular detection function\\nprint(\"object detection using detect()\")\\nimg_name = str(image_id) + \".png\" # \".jpg\"\\nimport utils.utils as utils\\nimport utils.visualize as visualize\\ncoco_class_names = [\\'BG\\', \\'cell\\']\\nRESULT_DIR = os.path.join(ROOT_DIR, \"mrcnn_result\")\\nregular_results = model.detect([image], verbose=1)\\nreg_r = regular_results[0]\\n# print(\"reg r:\", reg_r)\\n# Visualize results\\nvisualize.save_image(image, img_name, reg_r[\\'rois\\'], reg_r[\\'masks\\'],\\n  reg_r[\\'class_ids\\'], reg_r[\\'scores\\'], coco_class_names,\\n  filter_classs_names=None, scores_thresh=0.1, \\n  save_dir=RESULT_DIR, mode=1)\\n\\nprint(\"Done\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFmKA2nQHvW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab035457-599b-46c8-a34d-d9200bf3e297"
      },
      "source": [
        "# demo r-rcnn\n",
        "!python demo_rrcnn.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet50\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        400\n",
            "DETECTION_MIN_CONFIDENCE       0\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  512\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  512\n",
            "IMAGE_MIN_SCALE                2.0\n",
            "IMAGE_RESIZE_MODE              pad64\n",
            "IMAGE_SHAPE                    [512 512   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               200\n",
            "MEAN_PIXEL                     [43.53 39.56 48.22]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           nucleus\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        2000\n",
            "POST_NMS_ROIS_TRAINING         1000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
            "STEPS_PER_EPOCH                10\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           128\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               1\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:319: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:448: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/data/summer-project/LSTM_Mask_RCNN/detection_module/detect_model.py:834: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "2021-07-19 06:47:14.259686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-19 06:47:14.326351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:14.326946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-19 06:47:14.338078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-19 06:47:14.585918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-19 06:47:14.706844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-19 06:47:14.756829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-19 06:47:15.009179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-19 06:47:15.126646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-19 06:47:15.602918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-19 06:47:15.603136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.603843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.604360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-07-19 06:47:15.657383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-07-19 06:47:15.657711: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe66c4ebc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-19 06:47:15.657749: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-19 06:47:15.885284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.886110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe66c4ed80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-19 06:47:15.886142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-07-19 06:47:15.886323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.887109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-19 06:47:15.887223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-19 06:47:15.887270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-19 06:47:15.887300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-19 06:47:15.887332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-19 06:47:15.887359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-19 06:47:15.887385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-19 06:47:15.887410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-19 06:47:15.887507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.888343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.889005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-07-19 06:47:15.891789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-19 06:47:15.893396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-19 06:47:15.893429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-07-19 06:47:15.893442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-07-19 06:47:15.894441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.895227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-19 06:47:15.895845: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-19 06:47:15.895892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "LSTM Configurations:\n",
            "BATCH_SIZE                     1\n",
            "EPOCHS                         50\n",
            "FEATURE_SIZE                   1024\n",
            "GPU_COUNT                      1\n",
            "INPUT_SIZE                     1028\n",
            "L1_CELL_SIZE                   4096\n",
            "LEARNING_RATE                  1e-05\n",
            "MRCNNBBOX_SIZE                 4\n",
            "NAME                           None\n",
            "OUTPUT_SIZE                    4\n",
            "STEPS_PER_EPOCH                1000\n",
            "THRESHOLD                      0.15\n",
            "TIME_STEPS                     4\n",
            "VALIDATION_STEPS               50\n",
            "\n",
            "\n",
            "# Building LSTM inference model --------------- #\n",
            "\n",
            "tcmalloc: large alloc 1208123392 bytes == 0x55fec8400000 @  0x7fc2eb9871e7 0x7fc2dd113af0 0x7fc2e906c00b 0x7fc2e906c516 0x55fe4ed2d8a9 0x55fe4eda1b0a 0x55fe4ed9bc35 0x55fe4ec6de2c 0x7fc2e8e71ef7 0x55fe4ed2cf97 0x55fe4ed2cda0 0x55fe4eda0bb3 0x55fe4ed9bc35 0x55fe4ed2e73a 0x55fe4ed9d93b 0x55fe4ed9bc35 0x55fe4ed2efec 0x55fe4ed71e79 0x55fe4ed2d8a9 0x55fe4eda1b0a 0x55fe4ed9bc35 0x55fe4ed2e73a 0x55fe4ed9d93b 0x55fe4ed9bdcc 0x55fe4ed2e73a 0x55fe4ed9cd67 0x55fe4ed9c235 0x55fe4ed2edd1 0x55fe4ed2f1f1 0x55fe4ed9e318 0x55fe4ed9bdcc\n",
            "tcmalloc: large alloc 1208123392 bytes == 0x55fee0406000 @  0x7fc2eb9871e7 0x7fc2dd113af0 0x7fc2e906c00b 0x7fc2e906c516 0x55fe4ed2d8a9 0x55fe4eda1b0a 0x55fe4ed9bc35 0x55fe4ec6de2c 0x7fc2e8e71ef7 0x55fe4ed2cf97 0x55fe4ed2cda0 0x55fe4eda0bb3 0x55fe4ed9bc35 0x55fe4ed2e73a 0x55fe4ed9d93b 0x55fe4ed9bc35 0x55fe4ed2efec 0x55fe4ed71e79 0x55fe4ed2d8a9 0x55fe4eda1b0a 0x55fe4ed9bc35 0x55fe4ed2e73a 0x55fe4ed9d93b 0x55fe4ed9bdcc 0x55fe4ed2e73a 0x55fe4ed9cd67 0x55fe4ed9c235 0x55fe4ed2edd1 0x55fe4ed2f1f1 0x55fe4ed9e318 0x55fe4ed9bdcc\n",
            "Model: \"RRCNN\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (1, 4, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (1, 4, 1024)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        (1, 4096)            67207168    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)        (1, 4096)            83918848    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (1, 2048)            8390656     cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (1, 2048)            8390656     cu_dnnlstm_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (1, 1024)            2098176     dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (1, 1024)            2098176     dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (1, 2048)            0           dense_4[0][0]                    \n",
            "                                                                 dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (1, 4)               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (1, 4)               8196        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (1, 4)               0           lambda_4[0][0]                   \n",
            "                                                                 dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 172,111,876\n",
            "Trainable params: 172,111,876\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Image name: 0000.png\n",
            "\n",
            "# ------------------------------------ #\n",
            "# Build LSTM Model Time: 277.904\n",
            "# Processed Frames: 1\n",
            "# Cost Time: 0.588\n",
            "# FPS: 1.7\n",
            "# ------------------------------------ #\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}